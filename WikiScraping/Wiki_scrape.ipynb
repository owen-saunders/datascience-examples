{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia scraping and KMeans clustering\n",
    "The example below is taken and adapted from a workshop example from the University of Exeter. The example consisted of code only, explanations and commenting have been added for insights and learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outline\n",
    "This notebook takes 2 wikipedia pages and converts all the sentences in each page into a single line with '.' as the delimiter. The two pages are then put together to form a single corpus. The corpus is transformed into features, and the KMeans algorithm is used to find two distinct clusters which will predictably represent the two different wikipedia pages.\n",
    "\n",
    "Predictions are made for two newly introduced samples as to whether they are closer to cluster 0 or 1. That is, whether they are more likely to be written on the first or the second wikipedia page/article.\n",
    "\n",
    "##### Scikit Learn documentation\n",
    "About Term frequency times inverse document frequency (Tfidf)\n",
    "https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting\n",
    "\n",
    "About the KMeans clustering algorithm:\n",
    "https://scikit-learn.org/stable/modules/clustering.html#k-means\n",
    "\n",
    "About adjusted random scoring: \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html#sklearn.metrics.adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top teams per cluster:\n",
      "Cluster 0\n",
      " pizza\n",
      " dough\n",
      " oven\n",
      " baked\n",
      " cheese\n",
      " crust\n",
      " bread\n",
      " similar\n",
      " ingredients\n",
      " pizzas\n",
      "\n",
      "Cluster 1\n",
      " university\n",
      " exeter\n",
      " campus\n",
      " college\n",
      " luke\n",
      " school\n",
      " students\n",
      " streatham\n",
      " centre\n",
      " student\n",
      "\n",
      "Prediction for \"I live in Devon\": [1]\n",
      "Prediction for \"You cook it in the oven\": [0]\n"
     ]
    }
   ],
   "source": [
    "# Obtain formatted wiki pages for Exeter and Pizza\n",
    "p_wiki = wikipedia.page(\"University_of_Exeter\")\n",
    "page_1 = p_wiki.content.replace(\"\\n\", \"\").split(sep='.')\n",
    "\n",
    "p_wiki = wikipedia.page(\"Pizza\")\n",
    "page_2 = p_wiki.content.replace(\"\\n\", \"\").split(sep='.')\n",
    "\n",
    "# Create a single corpus and define each word as separate features\n",
    "documents = page_1 + page_2\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Create clusters with KMeans\n",
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, max_iter=100)\n",
    "model.fit(X)\n",
    "\n",
    "# Display features for each cluster\n",
    "print(\"Top teams per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d\" % i),\n",
    "    #print(terms) # Every feature in the cluster\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print()\n",
    "\n",
    "# Predict labels for samples\n",
    "Y = vectorizer.transform([\"I live in Devon.\"])\n",
    "prediction = model.predict(Y)\n",
    "print('Prediction for \"I live in Devon\":',prediction)\n",
    "\n",
    "Y = vectorizer.transform([\"You cook it in the oven\"])\n",
    "prediction = model.predict(Y)\n",
    "print('Prediction for \"You cook it in the oven\":',prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
